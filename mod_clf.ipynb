{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mod-clf.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyN6/sd+dHC10lTxIl+ghH7F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1184022880com/TEST/blob/master/mod_clf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4nWKUSSdgxh"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "os.symlink('/gdrive/My Drive', '/content/gdrive')\n",
        "!ls -l /content/gdrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3EnqPnmfETV"
      },
      "source": [
        "%matplotlib inline\n",
        "import os,random\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import keras.models as models\n",
        "from keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
        "from keras.layers.noise import GaussianNoise\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.regularizers import *\n",
        "from keras.optimizers import *\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import  random, sys, keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV9s47WSfOZp"
      },
      "source": [
        "import pickle as pk\n",
        "f=open('/content/gdrive/RML2016.10a_dict.pkl','rb')\n",
        "Xd=pk.load(f,encoding='latin1')\n",
        "#snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1,0])\n",
        "mods,snrs = [sorted(list(set([k[j] for k in Xd.keys()]))) for j in [0,1] ]\n",
        "X = []  \n",
        "lbl = []\n",
        "for mod in mods:\n",
        "    for snr in snrs:\n",
        "        X.append(Xd[(mod,snr)])\n",
        "        for i in range(Xd[(mod,snr)].shape[0]):  lbl.append((mod,snr))\n",
        "X = np.vstack(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qx0UaE4JuKv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-K4YD29fXcE"
      },
      "source": [
        "np.random.seed(2016)\n",
        "n_examples = X.shape[0]\n",
        "n_train = n_examples * 0.5\n",
        "train_idx = np.random.choice(range(0,n_examples), size=int(n_train), replace=False)\n",
        "test_idx = list(set(range(0,n_examples))-set(train_idx))\n",
        "X_train = X[train_idx]\n",
        "X_test =  X[test_idx]\n",
        "\n",
        "def to_onehot(yy):\n",
        "    yy1 = np.zeros([len(yy), len(mods)])#map可以强制转换成list，这样可以求len\n",
        "    yy1[np.arange(len(yy)), yy] = 1#arange创建长度指定的等差数列\n",
        "    return yy1\n",
        "Y_train = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), train_idx)))\n",
        "Y_test = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), test_idx)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3rZp1rcfeTt"
      },
      "source": [
        "classes = mods\n",
        "in_shp = list(X_train.shape[1:])\n",
        "dr = 0.5 # dropout rate取0.5~0.3可以较好顾及鲁棒性，同时不丢掉重要特征。也不会出现过拟合\n",
        "model = models.Sequential()\n",
        "model.add(Reshape([1]+in_shp, input_shape=in_shp))\n",
        "model.add(ZeroPadding2D((0, 2)))\n",
        "# stride ，在 2.0 中要用 （） 包起来,同时padding选择same，保证输出前后的尺寸一样\n",
        "model.add(Conv2D(256, (1, 3), padding='same', activation=\"relu\", name=\"conv1\", kernel_initializer='glorot_uniform'))\n",
        "model.add(Dropout(dr))\n",
        "model.add(ZeroPadding2D((0, 2)))\n",
        "model.add(Conv2D(80, (2, 3), padding=\"same\", activation=\"relu\", name=\"conv2\", kernel_initializer='glorot_uniform'))\n",
        "model.add(Dropout(dr))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu', kernel_initializer='he_normal', name=\"dense1\"))\n",
        "model.add(Dropout(dr))\n",
        "model.add(Dense( len(classes), kernel_initializer='he_normal', name=\"dense2\" ))\n",
        "model.add(Activation('softmax'))\n",
        "model.add(Reshape([len(classes)]))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpUmlOY9fqud"
      },
      "source": [
        "nb_epoch = 100     # 使用全部数据集训练一次的次数为100\n",
        "batch_size = 1024  # 每次训练一批的大小\n",
        "filepath = 'convmodrecnets_CNN2_0.5.wts.h5'\n",
        "history = model.fit(X_train,\n",
        "    Y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=nb_epoch,\n",
        "    #show_accuracy=True,\n",
        "    verbose=2,\n",
        "    validation_data=(X_test, Y_test),\n",
        "    callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto'),\n",
        "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
        "    ]\n",
        "    )\n",
        "model.load_weights(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1BSiYBH3OYT"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test,verbose=0, batch_size=batch_size)\n",
        "print (score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0H7_vqGNMSi"
      },
      "source": [
        "plt.figure()\n",
        "plt.title('Training performance')\n",
        "plt.plot(history.epoch, history.history['loss'], label='train loss+error')\n",
        "plt.plot(history.epoch, history.history['val_loss'], label='val_error')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vi4HRwJN5lH"
      },
      "source": [
        "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(labels))\n",
        "    plt.xticks(tick_marks, labels, rotation=45)\n",
        "    plt.yticks(tick_marks, labels)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOE9ZFUiN9pT"
      },
      "source": [
        "test_Y_hat = model.predict(X_test, batch_size=batch_size)\n",
        "conf = np.zeros([len(classes),len(classes)])\n",
        "confnorm = np.zeros([len(classes),len(classes)])\n",
        "for i in range(0,X_test.shape[0]):\n",
        "    j = list(Y_test[i,:]).index(1)\n",
        "    k = int(np.argmax(test_Y_hat[i,:]))\n",
        "    conf[j,k] = conf[j,k] + 1\n",
        "for i in range(0,len(classes)):\n",
        "    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
        "plot_confusion_matrix(confnorm, labels=classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaKJqMiPOC2S"
      },
      "source": [
        "#acc = {}\n",
        "#for snr in snrs:\n",
        "  # test_SNRs = map(lambda x: lbl[x][1], test_idx)\n",
        "  # test_X_i = X_test[np.where(np.array(test_SNRs)==snr)]\n",
        "  # test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]\n",
        "  # test_X_i.shape \n",
        "  # test_Y_i.shape   \n",
        "  # test_Y_i_temp = model.predict(test_X_i, batch_size=1024)\n",
        "  # conf = np.zeros([len(classes),len(classes)])\n",
        "  # confnorm = np.zeros([len(classes),len(classes)])\n",
        "  # for i in range(0,test_X_i.shape[0]):\n",
        "  #     j = list(test_Y_i[i,:]).index(1)\n",
        "  #     k = int(np.argmax(test_Y_i_temp[i,:]))\n",
        "  #     conf[j,k] = conf[j,k] + 1\n",
        "  # for i in range(0,len(classes)):\n",
        "  #     confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
        "  # plt.figure()\n",
        "  # plot_confusion_matrix(confnorm, labels=classes, title=\"ConvNet Confusion Matrix (SNR=%d)\"%(snr))\n",
        "  # cor = np.sum(np.diag(conf))\n",
        "  # ncor = np.sum(conf) - cor\n",
        "  # print (\"Overall Accuracy: \", cor / (cor+ncor))\n",
        "  # acc[snr] = 1.0*cor/(cor+ncor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqDWfKcGXYKV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO6nIRbgXJBQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiPEXmySRn4-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}